{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementing a U-Net architecture for image segmentation using TensorFlow and Keras:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "from google.colab import drive: This line imports the drive module from the google.colab package. This module contains functionality to mount Google Drive within a Google Colab notebook.\n",
        "drive.mount('/content/drive'): This line calls the mount() function from the drive module, which mounts the user's Google Drive to the specified directory (/content/drive in this case). After running this command, you'll be prompted to authenticate and grant permissions to access your Google Drive. Once authenticated, your Google Drive will be mounted, and you can access its contents through the specified directory path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORINCBVUQRN0",
        "outputId": "509c7dee-9d98-4b1f-c3d6-8a36396a42d4"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary module from Google Colab to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Mounting Google Drive to the '/content/drive' directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "basePath = \"/content/drive/MyDrive/Kvasir-SEG\": This line assigns the base path where the dataset is located in Google Drive to the variable basePath.\n",
        "def address(path=''): This line defines a function named address that takes an optional path argument. If no path is provided, it defaults to an empty string.\n",
        "return f\"{basePath}/{path}\": Inside the function, this line constructs the full address by combining the basePath and the provided path (if any) using f-string formatting. The resulting address is then returned by the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "syfthq9HQiip"
      },
      "outputs": [],
      "source": [
        "# Define the base path where the dataset is located in Google Drive\n",
        "basePath = \"/content/drive/MyDrive/Kvasir-SEG\"\n",
        "\n",
        "# Define a function to construct the full address based on the base path and additional path\n",
        "def address (path=''):\n",
        "    return f\"{basePath}/{path}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code begins by importing necessary libraries and modules.\n",
        "Libraries such as NumPy (np), Pandas (pd), and tqdm are imported for numerical operations, data processing, and progress tracking, respectively.\n",
        "TensorFlow and Keras modules are imported for deep learning operations.\n",
        "skimage, PIL, and matplotlib.pyplot are imported for image processing and visualization.\n",
        "The base path for the dataset is defined as basePath.\n",
        "A function named address is defined to construct the full address based on the base path and additional path provided as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xt1M1N65Qq02"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np  # For numerical operations\n",
        "import pandas as pd # For data processing and CSV file I/O\n",
        "from tqdm import tqdm # For progress tracking\n",
        "import os # For interacting with the operating system\n",
        "\n",
        "# Deep learning framework imports\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, Dense, Dropout, Activation, ZeroPadding2D, BatchNormalization, Concatenate, Flatten, Conv2D, AveragePooling2D, MaxPool2D, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Reshape\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "\n",
        "# Additional image processing imports\n",
        "from skimage.color import rgb2gray as rtg # For converting RGB images to grayscale\n",
        "from skimage.io import imread, imshow # For reading and displaying images\n",
        "from skimage.transform import resize # For resizing images\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.morphology import label # For labeling connected components in an image\n",
        "from PIL import Image # For image manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "os.walk() is a function used to traverse a directory tree, generating the file names in a directory tree by walking either top-down or bottom-up.\n",
        "In this loop, dirname represents the current directory being processed, _ represents any subdirectories (which are ignored), and filenames represents the list of files in the current directory.\n",
        "tqdm(total=len(filenames)) creates a progress bar with a total count equal to the number of files (len(filenames)) in the current directory.\n",
        "print(f\"[INFO] Successfully imported directory: {dirname}\") prints information about the directory being processed.\n",
        "The inner loop iterates over each filename in the current directory, updating the progress bar with t.update(1) for each file processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD4Px1XpQxAj",
        "outputId": "4fe47166-fb00-490e-9ae2-a90515aa9661"
      },
      "outputs": [],
      "source": [
        "# Iterate over directories, subdirectories, and files in the specified directory and its subdirectories\n",
        "for dirname, _, filenames in os.walk(address(\"..\")):\n",
        "    # Initialize a tqdm progress bar with the total number of files in the current directory\n",
        "    with tqdm(total=len(filenames)) as t:\n",
        "        # Print information about the successfully imported directory\n",
        "        print(f\"[INFO] Successfully imported directory: {dirname}\")\n",
        "        # Iterate over the filenames in the current directory\n",
        "        for filename in filenames:\n",
        "            # Update the progress bar for each file processed\n",
        "            t.update(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "mainDirPath = address() sets the variable mainDirPath to the base directory path retrieved using the address() function defined earlier.\n",
        "imagesPath = mainDirPath + \"/images\" creates the path for the directory containing images within the main directory (mainDirPath).\n",
        "masksPath = mainDirPath + \"/masks\" creates the path for the directory containing masks within the main directory (mainDirPath)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j-6eOlNUQ5lB"
      },
      "outputs": [],
      "source": [
        "# Define the main directory path based on the base path\n",
        "mainDirPath = address()\n",
        "\n",
        "# Define the paths for images and masks directories within the main directory\n",
        "imagesPath = mainDirPath + \"/images\"\n",
        "masksPath = mainDirPath + \"/masks\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "os.listdir(directory) returns a list containing the names of the entries in the directory given by directory.\n",
        "len(os.listdir(imagesPath)) calculates the total number of files (images) in the imagesPath directory.\n",
        "len(os.listdir(masksPath)) calculates the total number of files (masks) in the masksPath directory.\n",
        "Finally, the print statement displays the total number of images and masks found in their respective directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2RjXL9XQ7DK",
        "outputId": "0b0e1afa-1e18-4193-9c92-cbe0d4a2bf67"
      },
      "outputs": [],
      "source": [
        "# Print the total number of images and masks in their respective directories\n",
        "print(f\"Total images: {len(os.listdir(imagesPath))}\\nTotal masks: {len(os.listdir(masksPath))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function plot_training is designed to visualize the training and validation metrics (loss and accuracy) over epochs.\n",
        "It extracts the training and validation metrics from the history object returned by the fit() method of a Keras model.\n",
        "It finds the epoch with the lowest validation loss and the epoch with the highest validation accuracy.\n",
        "It plots the training and validation loss in one plot and the training and validation accuracy in another plot, with markers indicating the epochs with the lowest validation loss and the highest validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RNC74_CHQ-d8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_training(hist):\n",
        "    # Extracting training and validation metrics from the history object\n",
        "    tr_acc = hist.history['accuracy'] # Training accuracy\n",
        "    tr_loss = hist.history['loss']  # Training loss\n",
        "    val_acc = hist.history['val_accuracy']  # Validation accuracy\n",
        "    val_loss = hist.history['val_loss']  # Validation loss\n",
        "    \n",
        "    # Finding the index of the epoch with the lowest validation loss\n",
        "    index_loss = np.argmin(val_loss)\n",
        "    # Extracting the lowest validation loss value\n",
        "    val_lowest = val_loss[index_loss]\n",
        "    \n",
        "    # Finding the index of the epoch with the highest validation accuracy\n",
        "    index_acc = np.argmax(val_acc)\n",
        "    # Extracting the highest validation accuracy value\n",
        "    acc_highest = val_acc[index_acc]\n",
        "    \n",
        "    # Creating a list of epochs\n",
        "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "    \n",
        "    # Creating labels for the lowest validation loss and highest validation accuracy\n",
        "    loss_label = f'Best epoch= {str(index_loss + 1)}'\n",
        "    acc_label = f'Best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "    # Plotting the training and validation loss\n",
        "    plt.style.use('seaborn-dark')\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(Epochs, tr_loss, 'orange', label='Training loss')\n",
        "    plt.plot(Epochs, val_loss, 'blue', label='Validation loss')\n",
        "    plt.scatter(index_loss + 1, val_lowest, s=150, c='red', label=loss_label)\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Plotting the training and validation accuracy\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(Epochs, tr_acc, 'orange', label='Training Accuracy')\n",
        "    plt.plot(Epochs, val_acc, 'blue', label='Validation Accuracy')\n",
        "    plt.scatter(index_acc + 1 , acc_highest, s=150, c='red', label=acc_label)\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "os.walk(directory) generates the file names in a directory tree by walking either top-down or bottom-up. It returns a tuple of directory path, directory names, and file names.\n",
        "next(os.walk(imagesPath))[2] gets the third element of the tuple returned by os.walk(imagesPath), which contains the list of file names in the imagesPath directory.\n",
        "next(os.walk(masksPath))[2] does the same for the masksPath directory.\n",
        "So, images_ids and masks_ids contain lists of filenames (ids) of images and masks, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zifCK0NVRRmQ"
      },
      "outputs": [],
      "source": [
        "# Retrieve the list of filenames (ids) of images in the imagesPath directory\n",
        "images_ids = next(os.walk(imagesPath))[2]\n",
        "# Retrieve the list of filenames (ids) of masks in the masksPath directory\n",
        "masks_ids = next(os.walk(masksPath))[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "np.zeros() is a NumPy function that creates an array filled with zeros.\n",
        "For X, the shape (len(images_ids), 256, 256, 3) indicates the number of images, image height, image width, and number of channels (RGB).\n",
        "For Y, the shape (len(masks_ids), 256, 256, 1) indicates the number of masks, mask height, mask width, and a single channel for binary mask.\n",
        "dtype=np.uint8 specifies the data type as unsigned 8-bit integer, suitable for storing pixel values in the range [0, 255] for images.\n",
        "dtype=np.bool_ specifies the data type as Boolean, suitable for representing binary mask values (True/False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PYrKlhpTRURL"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty NumPy array for storing image data\n",
        "# The shape is determined by the number of images, image dimensions (256x256), and number of channels (3 for RGB)\n",
        "# The data type is set to uint8 (unsigned 8-bit integer) to represent pixel values in the range [0, 255]\n",
        "X = np.zeros((len(images_ids), 256, 256, 3), dtype=np.uint8)\n",
        "\n",
        "# Initialize an empty NumPy array for storing mask data\n",
        "# The shape is determined by the number of masks, image dimensions (256x256), and a single channel (binary mask)\n",
        "# The data type is set to bool_ (Boolean) to represent binary mask values (True/False)\n",
        "Y = np.zeros((len(masks_ids), 256, 256, 1), dtype=np.bool_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code iterates over the image IDs (images_ids) using enumerate() to also get the index of each image.\n",
        "For each image, it constructs the full path to the image file (path).\n",
        "It reads the image using imread() and selects only the RGB channels.\n",
        "The image is resized to the desired dimensions (256x256) using resize().\n",
        "The resized image is stored in the X array at index n.\n",
        "Similarly, for each image, it initializes an empty mask array, reads the corresponding mask image, converts it to grayscale, resizes it to the desired dimensions (256x256), and stores the resized mask in the Y array at index n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q5cvpxCRXff",
        "outputId": "69d97048-5826-4901-afcb-4087c5134919"
      },
      "outputs": [],
      "source": [
        "print(\"Resizing training images and masks\")\n",
        "\n",
        "# Iterate over the image IDs and their corresponding indices\n",
        "for n, id_ in tqdm(enumerate(images_ids), total=len(images_ids)):\n",
        "    # Construct the path to the image file\n",
        "    path = imagesPath + \"/\" + id_\n",
        "    \n",
        "    # Read the image using imread and select only the RGB channels\n",
        "    img = imread(path)[:, :, :3]\n",
        "    \n",
        "    # Resize the image to the desired dimensions (256x256)\n",
        "    img = resize(img, (256, 256), mode=\"constant\", preserve_range=True)\n",
        "    \n",
        "    # Store the resized image in the X array\n",
        "    X[n] = img\n",
        "    \n",
        "    # Initialize an empty mask array\n",
        "    mask = np.zeros((256, 256, 1), dtype=np.bool_)\n",
        "    \n",
        "    # Read the mask image\n",
        "    mask = imread(masksPath + \"/\" + id_)\n",
        "    \n",
        "    # Convert the mask image to grayscale\n",
        "    mask = rtg(mask)\n",
        "    \n",
        "    # Resize the mask image to the desired dimensions (256x256)\n",
        "    mask = np.expand_dims(resize(mask, (256, 256), mode=\"constant\", preserve_range=True), axis=-1)\n",
        "    \n",
        "    # Store the resized mask in the Y array\n",
        "    Y[n] = mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "X.shape returns the shape of the array X, which represents the training images. It is a tuple containing the number of images, image height, image width, and number of channels (3 for RGB).\n",
        "Y.shape returns the shape of the array Y, which represents the corresponding masks for the training images. It is a tuple containing the number of masks, mask height, mask width, and a single channel for binary masks.\n",
        "The print statement displays these shapes for both X and Y in a formatted string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xwvT0QRZZB",
        "outputId": "15ae9645-d6be-41a8-857b-000a0b7a05cd"
      },
      "outputs": [],
      "source": [
        "# Print the shapes of the training images and masks\n",
        "print(f\"X_train.shape: {X.shape}\\nY_train.shape: {Y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "random.randint(0, len(images_ids)) generates a random integer between 0 and the total number of images.\n",
        "X[image_x] retrieves the image corresponding to the randomly selected index image_x.\n",
        "imshow() displays the image.\n",
        "plt.show() displays the image plot.\n",
        "np.squeeze(Y[image_x]) removes single-dimensional entries from the shape of the array Y[image_x].\n",
        "plt.imshow() displays the mask.\n",
        "plt.show() displays the mask plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "v9KfQHLORdkG",
        "outputId": "95ecb8c0-163e-4ace-a930-2cda24ba5a0b"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Randomly select an image index\n",
        "image_x = random.randint(0, len(images_ids))\n",
        "\n",
        "# Display the randomly selected image\n",
        "imshow(X[image_x])\n",
        "\n",
        "# Display the corresponding mask for the selected image\n",
        "plt.show()\n",
        "plt.imshow(np.squeeze(Y[image_x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "X[:900] selects the first 900 images from the array X, which is the training set.\n",
        "Y[:900] selects the corresponding masks for the first 900 images, which form the training set.\n",
        "X[900:] selects the images from index 900 onwards, which form the validation set.\n",
        "Y[900:] selects the corresponding masks for the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ikHl171rRfzL"
      },
      "outputs": [],
      "source": [
        "# Define training and validation sets for images and masks\n",
        "x_train = X[:900] # Take the first 900 images for training\n",
        "y_train = Y[:900] # Take the corresponding masks for training\n",
        "x_val = X[900:]  # Take the remaining images for validation\n",
        "y_val = Y[900:] # Take the corresponding masks for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0QMQtpKxN9Qi"
      },
      "outputs": [],
      "source": [
        "# Define the input layer with shape (256, 256, 3)\n",
        "input = tf.keras.layers.Input((256, 256, 3))\n",
        "\n",
        "# Normalize input images to the range [0,1]\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 256)(input)\n",
        "\n",
        "# Contracting path\n",
        "# Downward path with convolutional and max pooling layers to extract features\n",
        "c1 = tf.keras.layers.Conv2D(8, (3, 3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(s)\n",
        "c1 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "c3 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "c4 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "c5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "# Expansive path\n",
        "# Upward path with transpose convolutional layers and skip connections\n",
        "u6 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "u7 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1])\n",
        "c9 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "# Output layer with sigmoid activation function for binary classification\n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "# Define the U-Net model\n",
        "modelUNet = tf.keras.Model(inputs=input, outputs=outputs, name='U-NET')\n",
        "\n",
        "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
        "modelUNet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvkf54ZqRqKL",
        "outputId": "3e6f2d80-3209-4fd5-d785-3b142cad7b7e"
      },
      "outputs": [],
      "source": [
        "modelUNet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Callbacks are functions that can be applied at different stages of the training process. They can be used to perform tasks like logging training statistics, saving model checkpoints, and stopping training early if certain conditions are met.\n",
        "In this code, we define a callback using tf.keras.callbacks.TensorBoard to log training statistics. The log_dir parameter specifies the directory where the logs will be written.\n",
        "The fit method is then called on the modelUNet object to train the model on the provided data (x_train and y_train).\n",
        "During training, the model will use 1% of the training data for validation (validation_split=0.01).\n",
        "The batch_size parameter determines the number of samples that will be processed before updating the model's weights.\n",
        "The epochs parameter specifies the number of times the entire dataset will be passed through the model during training.\n",
        "The callbacks parameter is used to specify the list of callbacks to be applied during training. In this case, we pass the list containing the TensorBoard callback we defined earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo7wgyyQRuOV",
        "outputId": "c8548422-30e9-40a9-fc23-e5f8809299ca"
      },
      "outputs": [],
      "source": [
        "# Callbacks are objects that can perform actions at various stages of training (e.g., at the start or end of each epoch)\n",
        "# Here, we define a callback to log training statistics using TensorBoard\n",
        "callbacks=[tf.keras.callbacks.TensorBoard(log_dir=\"logs\")]\n",
        "\n",
        "# The `fit` method trains the U-Net model on the training data\n",
        "# It takes the input data (`x_train`) and corresponding target data (`y_train`)\n",
        "# `validation_split=0.01` specifies that 1% of the training data will be used for validation\n",
        "# `batch_size=8` specifies the number of samples per gradient update\n",
        "# `epochs=30` specifies the number of epochs (iterations over the entire dataset) for training\n",
        "# `callbacks=callbacks` specifies the list of callbacks to apply during training (in this case, the TensorBoard callback)\n",
        "results = modelUNet.fit(x_train, y_train, validation_split=0.01, batch_size=8, epochs=30, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function call will generate plots showing the training and validation loss over epochs, as well as the training and validation accuracy over epochs, if implemented within the plot_training() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jwhrhu0RRxZZ",
        "outputId": "5eaa00e1-6515-4d3e-9fb0-76c6f553f3e0"
      },
      "outputs": [],
      "source": [
        "# Plot the training history using the `plot_training` function\n",
        "plot_training(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The evaluate method is used to evaluate the performance of a trained model on a test dataset.\n",
        "In this code, modelUNet is the trained U-Net model that we want to evaluate.\n",
        "X is the input test data (images), and Y is the corresponding ground truth data (masks).\n",
        "The method computes the loss value and any other metrics specified during model compilation (e.g., accuracy).\n",
        "The evaluation results are returned as a list, where the first element is the loss value and subsequent elements are the values of the specified metrics.\n",
        "These results can be used to assess how well the model generalizes to unseen data and to compare the model's performance with different configurations or architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWK7sHA9R2Mz",
        "outputId": "2d39c2dc-0ece-4aab-c36d-5ccde025e74b"
      },
      "outputs": [],
      "source": [
        "# The `evaluate` method evaluates the trained U-Net model on the given test data (X and Y).\n",
        "# It computes the loss value and metrics (specified during model compilation) for the test dataset.\n",
        "# The evaluation results are returned as a list containing the loss value and metrics values.\n",
        "modelUNet.evaluate(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code calculates the confusion matrix to evaluate the performance of the U-Net model on the validation data.\n",
        "The predict method is used to generate predictions (y_pred) for the validation images (x_val).\n",
        "The predicted masks are binarized using a threshold of 0.5 to convert them into binary format (y_pred_binary).\n",
        "Similarly, the ground truth masks (y_val) are converted into binary format (y_val_binary).\n",
        "The confusion matrix is computed using the confusion_matrix function from the scikit-learn library.\n",
        "The computed confusion matrix is visualized as a heatmap using the heatmap function from the seaborn library.\n",
        "The heatmap provides a graphical representation of the confusion matrix, where each cell represents the count of true positives, false positives, true negatives, and false negatives. The intensity of the color indicates the count, and annotations provide the exact count values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "fW79YH7zHAft",
        "outputId": "1e8031e1-5a19-467d-e5c8-c228ede49394"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict masks for validation data using the trained U-Net model\n",
        "y_pred = modelUNet.predict(x_val)\n",
        "\n",
        "# Convert predicted masks to binary format using a threshold of 0.5\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Convert ground truth masks to binary format\n",
        "y_val_binary = y_val.astype(int)\n",
        "\n",
        "# Compute the confusion matrix using sklearn\n",
        "cm = confusion_matrix(y_val_binary.flatten(), y_pred_binary.flatten())\n",
        "\n",
        "# Plot the confusion matrix as a heatmap using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code calculates the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) to evaluate the performance of the U-Net model for binary classification.\n",
        "The roc_curve function from scikit-learn computes the ROC curve by taking the true labels (y_val.flatten()) and predicted probabilities (y_pred.flatten()).\n",
        "The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1 - specificity) at various threshold settings.\n",
        "The auc function computes the AUC score, which quantifies the overall performance of the model. AUC ranges from 0 to 1, where a higher value indicates better performance.\n",
        "Finally, the ROC curve is plotted using plt.plot. The label of the curve includes the computed AUC value for reference. Axis labels, title, and legend are added to the plot for better interpretation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "NN4n6cN2Rgu0",
        "outputId": "681820e6-e709-4e48-da4b-0381cf6197cf"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Calculate ROC curve\n",
        "# ROC curve is a graphical representation of the true positive rate (sensitivity) versus the false positive rate (1 - specificity)\n",
        "# It shows the trade-off between sensitivity and specificity across different threshold values\n",
        "fpr, tpr, _ = roc_curve(y_val.flatten(), y_pred.flatten())\n",
        "\n",
        "# Calculate AUC (Area Under the Curve)\n",
        "# AUC quantifies the overall performance of a binary classification model\n",
        "# It represents the probability that a randomly chosen positive sample will be ranked higher than a randomly chosen negative sample\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "# The ROC curve is plotted with false positive rate (x-axis) against true positive rate (y-axis)\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The calculate_iou function computes the Intersection over Union (IoU) score between true and predicted masks.\n",
        "Intersection is calculated by finding the pixels where both true and predicted masks are non-zero (logical AND operation).\n",
        "Union is calculated by finding the pixels where either true or predicted masks are non-zero (logical OR operation).\n",
        "IoU score is computed as the ratio of the intersection area to the union area.\n",
        "The code then calculates IoU scores for different thresholds (ranging from 0.1 to 1.0 with a step size of 0.1) using list comprehension.\n",
        "For each threshold value, the predicted mask is binarized based on whether the predicted probability is above the threshold.\n",
        "Finally, the IoU scores are plotted against the threshold values to visualize the IoU curve, which helps in determining the optimal threshold for segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "595zMbJMRn6_",
        "outputId": "118d3d2d-ed48-4906-fce3-0770f1e3475b"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(y_true, y_pred):\n",
        "    # Calculate intersection and union between true and predicted masks\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    \n",
        "    # Calculate Intersection over Union (IoU) score\n",
        "    # IoU measures the overlap between the true and predicted masks\n",
        "    iou_score = np.sum(intersection) / np.sum(union)\n",
        "    return iou_score\n",
        "\n",
        "\n",
        "# Calculate IoU for different thresholds\n",
        "# IoU is calculated for various threshold values to evaluate the model's segmentation performance at different confidence levels\n",
        "thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "iou_scores = [calculate_iou(y_val_binary, (y_pred > threshold).astype(int)) for threshold in thresholds]\n",
        "\n",
        "# Plot IoU curve\n",
        "# IoU scores are plotted against different threshold values\n",
        "plt.plot(thresholds, iou_scores, marker='.')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('IoU')\n",
        "plt.title('IoU Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code iterates over each image in the validation dataset using a for loop.\n",
        "For each image, it retrieves the original image (img) and generates a predicted mask (predMask) using the trained U-Net model (modelUNet.predict()).\n",
        "It then creates a new figure (fig) to visualize the original image, predicted mask, and original mask.\n",
        "Three subplots are added to the figure:\n",
        "   1) The first subplot (ax1) displays the predicted mask using the 'cividis' colormap.\n",
        "   2) The second subplot (ax2) displays the original image in grayscale.\n",
        "   3) The third subplot (ax3) displays the original mask using the 'bone' colormap.\n",
        "Axis labels are turned off for all subplots.\n",
        "After iterating over all images, the plot with all images is shown using plt.show()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lP4G4iV9ryhI",
        "outputId": "0491d34c-6094-4e9d-adb2-dbe0a891be3d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Iterate over each image in the validation dataset\n",
        "for i in range( len(x_val)):\n",
        "    ind = i\n",
        "    img = x_val[ind]   # Get the original image\n",
        "    predMask = modelUNet.predict(np.expand_dims(img, axis=0), verbose=0)  # Generate predicted mask for the image\n",
        "\n",
        "    # Create a new figure for visualization\n",
        "    fig = plt.figure(figsize=(15, 5))  \n",
        "\n",
        "    # Add subplots for original image, predicted mask, and original mask\n",
        "    ax1 = fig.add_subplot(1, 3, 1)\n",
        "    ax1.set_title(\"pred mask\")\n",
        "    ax1.imshow(np.squeeze(predMask), cmap='cividis', interpolation='bicubic')  # Display predicted mask with 'cividis' colormap\n",
        "    ax1.axis('off')  # Turn off axis\n",
        "\n",
        "\n",
        "    ax2 = fig.add_subplot(1, 3, 2)\n",
        "    ax2.set_title(\"original image\")\n",
        "    ax2.imshow(x_val[ind], cmap='gray') # Display original image in grayscale\n",
        "    ax2.axis('off')   # Turn off axis\n",
        "\n",
        "\n",
        "    ax3 = fig.add_subplot(1, 3, 3)\n",
        "    ax3.set_title(\"original mask\")\n",
        "    ax3.imshow(np.squeeze(y_val[ind]), cmap='bone')  # Display original mask with 'bone' colormap\n",
        "    ax3.axis('off')  # Turn off axis\n",
        "\n",
        "# Show the plot with all images\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
